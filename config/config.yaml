# Generic Anomaly Data Quality (GADQ) Framework Configuration

# Databricks Configuration
databricks:
  host: "your-databricks-host"
  token: "your-databricks-token"
  cluster_id: "your-cluster-id"

# Fields to Profile
fields:
  # Amount fields
  amount:
    source_column: "amount"  # Original column name
    standardization: "cast(amount as decimal(20,2))"  # SQL expression to standardize
    metrics: ["min", "max", "mean", "stddev", "null_count", "percentiles"]
    percentiles: [25, 50, 75]
    anomaly_threshold: 3.0  # Z-score threshold for anomalies

  # Date fields
  transaction_date:
    source_column: "transaction_date"
    standardization: "to_date(transaction_date, 'yyyy-MM-dd')"
    metrics: ["min", "max", "null_count", "day_of_week_distribution"]
    anomaly_threshold: 3.0

  # String fields
  customer_name:
    source_column: "customer_name"
    standardization: "trim(upper(customer_name))"
    metrics: ["distinct_count", "null_count", "empty_count", "pattern_analysis"]
    pattern_analysis: true

  # Numeric fields
  discount:
    source_column: "discount"
    standardization: "coalesce(cast(discount as decimal(10,2)), 0.0)"
    metrics: ["min", "max", "mean", "stddev", "null_count"]
    anomaly_threshold: 3.0

# Custom Metrics
custom_metrics:
  - name: "unique_customers"
    expression: "count(distinct customer_id)"
    description: "Count of unique customers"

  - name: "completed_transactions"
    expression: "sum(case when status = 'completed' then 1 else 0 end)"
    description: "Count of completed transactions"

# Profiling Settings
profiling:
  sample_size: 0.1  # 10% of data for profiling
  batch_size: 1000  # Records per batch
  time_grain: "business_dt"  # Default time grain column

# Anomaly Detection Settings
anomaly:
  methods:
    - name: "statistical"
      enabled: true
      threshold: 3.0  # Z-score threshold

    - name: "machine_learning"
      enabled: true
      contamination: 0.1  # Expected proportion of outliers
      min_data_points: 100  # Minimum data points required

  lookback_days: 30  # Historical analysis window

# Storage Configuration
storage:
  catalog: "hive_metastore"
  schema: "default"
  tables:
    profiles: "data_profiles"
    anomalies: "anomaly_results"

# Logging Configuration
logging:
  level: "INFO"
  path: "logs/gadq.log"
  max_size: 10485760  # 10MB
  backup_count: 5 